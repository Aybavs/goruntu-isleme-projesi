#!/usr/bin/env python3
"""
Speech Detection Service - Ana modül
Ağız hareketi tespiti ile konuşma durumunu tespit eder ve gRPC üzerinden servis sağlar.
"""
import os
import grpc
import time
import argparse
from concurrent import futures
from pathlib import Path

# .env dosyasını yükle (varsa)
dotenv_path = Path(__file__).parent / '.env'
if dotenv_path.exists():
    from dotenv import load_dotenv
    load_dotenv(dotenv_path)

# Modülleri import et
from modules.utils import setup_logging, add_proto_path, check_dependencies
from modules.config import load_config
from modules.service import SpeechDetectionServicer

# Proto dosyaları dizinini ekle
add_proto_path()

# Proto dosyalarını import et
import proto.vision_pb2_grpc as vision_pb2_grpc

def parse_arguments():
    """
    Komut satırı argümanlarını işler
    
    Returns:
        argparse.Namespace: Komut satırı argümanları
    """
    parser = argparse.ArgumentParser(description='Speech Detection Service')
    parser.add_argument('--config', type=str, help='Konfigürasyon dosyası yolu')
    parser.add_argument('--host', type=str, help='Bağlanılacak host')
    parser.add_argument('--port', type=str, help='Kullanılacak port')
    parser.add_argument('--log-level', type=str, choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
                        help='Loglama seviyesi')
    parser.add_argument('--no-log-file', action='store_true', help='Dosyaya log yazma')
    
    return parser.parse_args()

def serve(config):
    """
    gRPC sunucusunu başlatır
    
    Args:
        config (dict): Konfigürasyon ayarları
    """
    # Sunucu parametreleri
    host = config.get('host', '0.0.0.0')
    port = config.get('port', '50053')
    address = f"{host}:{port}"
    max_workers = config.get('max_workers', 10)
    
    # Logger nesnesi
    logger = setup_logging(
        log_level=config.get('log_level', 'INFO'),
        log_to_file=config.get('log_to_file', True),
        log_file=config.get('log_file', 'speech_service.log')
    )
    
    # gRPC sunucusu oluştur
    server = grpc.server(
        futures.ThreadPoolExecutor(max_workers=max_workers),
        options=[
            ('grpc.max_send_message_length', 10 * 1024 * 1024),  # 10MB
            ('grpc.max_receive_message_length', 10 * 1024 * 1024)  # 10MB
        ]
    )
    
    # Speech Detection Service ekle
    speech_service = SpeechDetectionServicer(config)
    vision_pb2_grpc.add_SpeechDetectionServiceServicer_to_server(speech_service, server)
    
    # Portu bağla ve sunucuyu başlat
    server.add_insecure_port(address)
    server.start()
    
    logger.info(f"SpeechDetectionService gRPC sunucusu {address} adresinde çalışıyor...")
    
    try:
        server.wait_for_termination()
    except KeyboardInterrupt:
        logger.info("Sunucu kapatılıyor...")
        server.stop(0)
        logger.info("Sunucu kapatıldı.")
            total_change = (opening_change * 0.7) + (distance_change * 0.3)
            
            # Değişim geçmişini kaydet
            self.mouth_motion_history[face_id].append(total_change)
        
        # Mevcut değerleri güncelle
        self.last_features[face_id] = mouth_features.copy()

        # Yeterli veri yoksa basit bir kontrol yap
        if len(self.mouth_history[face_id]) < 5:
            # Başlangıç kontrolü
            raw_speaking = mouth_features['normalized_opening'] > 0.3 and mouth_features['avg_lip_distance'] > 3.0
            self.speaking_state[face_id] = raw_speaking
            return raw_speaking

        # Kişiye özel eşik değerini oluştur veya güncelle
        if face_id not in self.person_thresholds or len(self.mouth_history[face_id]) % 10 == 0:
            self._update_person_thresholds(face_id)

        # Mevcut değerler
        current_opening = mouth_features['normalized_opening']
        current_distance = mouth_features['avg_lip_distance']
        
        # Eşik değerleri
        thresholds = self.person_thresholds.get(face_id, {'opening': 0.2, 'distance': 2.0})
        
        # Hareket tespiti
        motion_detected = False
        if len(self.mouth_motion_history[face_id]) >= 4:
            # Son karelerdeki hareket miktarını analiz et
            recent_motion = list(self.mouth_motion_history[face_id])
            
            # Ortalama hareket ve varyans
            mean_motion = np.mean(recent_motion)
            motion_variance = np.var(recent_motion) if len(recent_motion) > 1 else 0
            
            # Hareket tespit kriterleri
            motion_detected = (mean_motion > self.min_variation_threshold) and (motion_variance > 0.0005)

        # Konuşma göstergeleri
        is_open = current_opening > thresholds.get('opening', 0.2)
        has_distance = current_distance > thresholds.get('distance', 2.0)
        
        # Değişim analizi
        recent_frames = min(8, len(self.mouth_history[face_id]))
        recent = self.mouth_history[face_id][-recent_frames:]
        
        # Açıklık değişimi
        openings = [frame['normalized_opening'] for frame in recent]
        opening_std = np.std(openings)
        opening_range = np.max(openings) - np.min(openings)
        
        # Değişim kriteri
        has_variation = (opening_std > self.min_variation_threshold) or (opening_range > 0.15)
        
        # Konuşma skoru hesaplama
        speaking_score = (0.35 * int(is_open) +            # Ağız açıklığı
                         0.20 * int(has_distance) +        # Dudaklar arası mesafe
                         0.25 * int(has_variation) +       # Değişim analizi
                         0.35 * int(motion_detected))      # Hareket tespiti
        
        # Skoru normalize et
        speaking_score = min(1.0, speaking_score)
        
        # Konuşma güven skorunu güncelle
        if speaking_score > 0.5:
            # Konuşma göstergeleri varsa güven skorunu arttır
            self.speaking_confidence[face_id] = min(1.0, self.speaking_confidence[face_id] + 0.12)
        elif speaking_score < 0.25:
            # Yoksa düşür
            self.speaking_confidence[face_id] = max(0.0, self.speaking_confidence[face_id] - 0.15)
        
        # Mevcut karara karar ver
        raw_speaking_state = self.speaking_confidence[face_id] > self.speaking_confidence_threshold
        
        # Soğuma süreci - ani değişimleri önlemek için
        if raw_speaking_state != self.speaking_state[face_id]:
            if self.transition_cooldown[face_id] >= self.cooldown_frames:
                self.speaking_state[face_id] = raw_speaking_state
                self.transition_cooldown[face_id] = 0
            else:
                self.transition_cooldown[face_id] += 1
        else:
            self.transition_cooldown[face_id] = 0
        
        return self.speaking_state[face_id]
    
    def _update_person_thresholds(self, face_id):
        """Kişiye özel konuşma eşiklerini günceller"""
        if len(self.mouth_history[face_id]) < 5:
            return
            
        # Geçmiş verilerden istatistikleri hesapla
        openings = [frame['normalized_opening'] for frame in self.mouth_history[face_id]]
        distances = [frame['avg_lip_distance'] for frame in self.mouth_history[face_id]]
        
        # Medyan değerler
        opening_median = np.median(openings)
        distance_median = np.median(distances)
        
        # Çeyrekler arası aralık (IQR)
        opening_q75 = np.percentile(openings, 75)
        opening_q25 = np.percentile(openings, 25)
        opening_iqr = opening_q75 - opening_q25
        
        # Dinlenme halindeki ağız açıklığı
        resting_opening = np.percentile(openings, 30)
        
        # Dinamik eşikler
        opening_thresh = resting_opening + (opening_iqr * 0.7)
        
        # Mesafe eşiği
        distance_thresh = distance_median * 1.15
        
        # Eşik değerlerini güncelle
        self.person_thresholds[face_id] = {
            'opening': max(0.15, opening_thresh),
            'distance': max(1.5, distance_thresh)
        }
        
    def update_speaking_time(self, face_id, is_speaking, current_time):
        """Konuşma süresini günceller"""
        if is_speaking:
            # Konuşmaya başladıysa başlangıç zamanını kaydet
            if face_id not in self.speaking_start_times:
                self.speaking_start_times[face_id] = current_time
        else:
            # Konuşmayı bitirdiyse süreyi hesapla ve ekle
            if face_id in self.speaking_start_times:
                elapsed = current_time - self.speaking_start_times[face_id]
                # Çok kısa süreli konuşmaları filtrele
                if elapsed > 0.5:  
                    self.speaking_durations[face_id] += elapsed
                del self.speaking_start_times[face_id]
                
    def get_speaking_time(self, face_id):
        """Konuşma süresini döndürür"""
        return self.speaking_durations[face_id]
        
    def clear_face_data(self, face_id):
        """Yüze ait verileri temizler"""
        if face_id in self.speaking_start_times:
            del self.speaking_start_times[face_id]
        if face_id in self.speaking_durations:
            del self.speaking_durations[face_id]
        if face_id in self.mouth_history:
            del self.mouth_history[face_id]
        if face_id in self.person_thresholds:
            del self.person_thresholds[face_id]
        if face_id in self.speaking_confidence:
            del self.speaking_confidence[face_id]
        if face_id in self.speaking_state:
            del self.speaking_state[face_id]


class SpeechDetectionServicer(vision_pb2_grpc.SpeechDetectionServiceServicer):
    def __init__(self):
        """Speech Detection Service sınıfını başlatır"""
        self.speech_detector = SpeechDetector(
            variation_threshold=float(os.getenv('VARIATION_THRESHOLD', '0.03')),
            confidence_threshold=float(os.getenv('SPEAKING_CONFIDENCE_THRESHOLD', '0.35')),
            cooldown_frames=int(os.getenv('COOLDOWN_FRAMES', '3'))
        )
        logger.info("Speech Detection Service başlatıldı")
    
    def DetectSpeech(self, request, context):
        """
        Vision Service'den gelen yüz verisini kullanarak konuşma tespiti yapar
        """
        try:
            face_id = request.face_id
            landmarks = list(request.landmarks)
            
            logger.info(f"Konuşma tespiti isteği alındı (Yüz ID: {face_id})")
            
            # Mevcut zaman
            current_time = time.time()
            
            # Konuşma durumunu tespit et
            is_speaking = self.speech_detector.detect_speaking(face_id, landmarks)
            
            # Konuşma süresini güncelle
            self.speech_detector.update_speaking_time(face_id, is_speaking, current_time)
            
            # Konuşma süresini al
            speaking_time = self.speech_detector.get_speaking_time(face_id)
            
            logger.info(f"Yüz ID {face_id} için konuşma durumu: {is_speaking}, süre: {speaking_time:.2f} sn")
            
            # Yanıt oluştur
            return vision_pb2.SpeechResponse(
                is_speaking=is_speaking,
                speaking_time=speaking_time,
                face_id=face_id
            )
            
        except Exception as e:
            logger.error(f"Konuşma tespiti hatası: {str(e)}")
            return vision_pb2.SpeechResponse(
                is_speaking=False,
                speaking_time=0.0,
                face_id=request.face_id
            )


def serve():
    """gRPC sunucusunu başlatır"""
    port = os.getenv('PORT', '50053')
    host = os.getenv('HOST', '0.0.0.0')
    address = f"{host}:{port}"
    max_workers = int(os.getenv('MAX_WORKERS', '10'))
    
    server = grpc.server(
        futures.ThreadPoolExecutor(max_workers=max_workers),
        options=[
            ('grpc.max_send_message_length', 10 * 1024 * 1024),  # 10MB
            ('grpc.max_receive_message_length', 10 * 1024 * 1024)  # 10MB
        ]
    )
    
    vision_pb2_grpc.add_SpeechDetectionServiceServicer_to_server(SpeechDetectionServicer(), server)
    server.add_insecure_port(address)
    server.start()
    logger.info(f"SpeechDetectionService gRPC server {address} adresinde çalışıyor...")
    server.wait_for_termination()


if __name__ == "__main__":
    serve()